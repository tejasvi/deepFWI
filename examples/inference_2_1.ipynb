{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single day FWI Reanalysis forecast using 2 day Forcings input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do single day FWI-Reanalysis forecast using 2-days input of Temperature, Relative humidity, Total precipitation, and Wind speed. The sample data must span for at least 2 consecutive days. The file format of the stored data should be in netCDF4 format. A pretrained model checkpoint conrresponding to the input and forecast timespan will be required as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing working directory to import modules naturally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src')\n",
    "from train import str2num, get_hparams, get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing installed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General functionality\n",
    "import random\n",
    "from glob import glob\n",
    "from argparse import Namespace\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "# Keep the execution uncomplicated\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ploting purposes\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "# Helper modules\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensuring reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2334\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating pickled list of test-set files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the files needed for output variable are specified.\n",
    "# Input variable files for corresponding dates are auto-deduced.\n",
    "test_out_files = [f'/nvme0/fwi-reanalysis/ECMWF_FWI_201904{x:02}_1200_hr_fwi_e5.nc' for x in range(1, 3)]\n",
    "print(\"First few files...\", *test_out_files[:3], sep='\\n')\n",
    "\n",
    "# Pickling the list which can be used later\n",
    "with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "    pickle.dump(test_out_files, tmp)\n",
    "    test_set_path = tmp.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting the knobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing hyperparamters and configuration in a dictionary\n",
    "hparams_dict = get_hparams(\n",
    "    # Feature density of U-Net layers\n",
    "    init_features=16,\n",
    "    # Number of input channels (=4*input days)\n",
    "    in_days=2,\n",
    "    # Number of prediction channels (=output days)\n",
    "    out_days=1,\n",
    "    # Loss metric\n",
    "    loss='mse',\n",
    "    # Batch size\n",
    "    batch_size=1,\n",
    "    # Number of GPUs to use\n",
    "    gpus=1,\n",
    "    # Turn on temporal and spatial constraints for case-study in Australia\n",
    "    case_study=False,\n",
    "    # Whether to ignore fire-prone regions\n",
    "    clip_fwi=False,\n",
    "    # Pickled list of output files in test-set\n",
    "    test_set=test_set_path,\n",
    "    # Model architecture\n",
    "    model='unet_tapered',\n",
    "    # Output dataloader\n",
    "    out='fwi_reanalysis',\n",
    "    # Directory with FWI Forcings input\n",
    "    forcings_dir='/nvme1/fwi-forcings',\n",
    "    # Directory with FWI Renanlysis output\n",
    "    reanalysis_dir='/nvme0/fwi-reanalysis',\n",
    "    # Custom mask stored as numpy array\n",
    "    mask=False,\n",
    "    # Model checkpoint file used to load the pretrained weights\n",
    "    checkpoint_file='/w/deepfwi/src/model/checkpoints/pre_trained/5/2_1/epoch_56_100.ckpt'\n",
    "    )\n",
    "\n",
    "# Converting the dictionary to Namespace for easier access\n",
    "hparams = Namespace(**hparams_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the flag for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.eval = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model architecture and attach with the data\n",
    "model = get_model(hparams)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model.load_state_dict(torch.load(hparams.checkpoint_file)[\"state_dict\"])\n",
    "\n",
    "# Turn off the gradients\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor\n",
    "x = model.data[0][0].unsqueeze(0)\n",
    "\n",
    "# Ground truth tensor\n",
    "y = model.data[0][1].unsqueeze(0)\n",
    "\n",
    "# Predicted tensor\n",
    "y_hat = model(x).detach()\n",
    "\n",
    "# Masking the prediction as done with the ground truth\n",
    "y_hat[torch.isnan(y)] = torch.tensor(float('nan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, hparams.in_days*4))\n",
    "fig.suptitle('Input FWI-variables from 2019-04-01 till 2019-04-02', fontsize=25)\n",
    "for i in range(hparams.in_days):\n",
    "    for j in range(4):\n",
    "        ax = fig.add_subplot(hparams.in_days, 4, 4*i+j+1)\n",
    "        if i==0:\n",
    "            if j==0:\n",
    "                ax.set_title('Relative Humidity',fontsize='23', pad=20)\n",
    "            elif j==1:\n",
    "                ax.set_title('Temperature',fontsize='23', pad=20)\n",
    "            elif j==2:\n",
    "                ax.set_title('Precipitation',fontsize='23', pad=20)\n",
    "            else:\n",
    "                ax.set_title('Wind speed',fontsize='23', pad=20)\n",
    "        if j==0:\n",
    "            ax.set_ylabel(f'2019-04-{i+1:02}', fontsize='23', labelpad=20)\n",
    "        if j==1:\n",
    "            plt.imshow(x.squeeze()[4*i+j], cmap='gist_ncar')\n",
    "        elif j==2:\n",
    "            plt.imshow(x.squeeze()[4*i+j], cmap='flag')\n",
    "        else:\n",
    "            plt.imshow(x.squeeze()[4*i+j], cmap='hsv')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Helper function to add colorbar in the plots.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im, title):\n",
    "    fig, ax = plt.subplots(figsize = (20,10))\n",
    "    fig.suptitle(title, fontsize=25)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('bottom', size='5%', pad=0.5)\n",
    "    im = ax.imshow(im, cmap='jet')\n",
    "    fig.colorbar(im, cax=cax, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(y.squeeze(), 'Observed FWI-reanalysis for 2019-04-02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(y_hat.squeeze(), f'Predicted FWI-reanalysis for 2019-04-02\\nAccuracy: \\\n",
    "{((y-y_hat).abs()<9.4)[model.data.mask.expand_as(y)].float().mean()*100:.2f}%*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>*Using half of MAD as the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot((y-y_hat).abs().squeeze(), f\"Error in predicted FWI-reanalysis for 2019-04-02\\nMAE: \\\n",
    "{((y-y_hat).abs())[model.data.mask.expand_as(y)].float().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The receptive field size for input stays the same as for global prediction. After getting the global predictions we extract only the values falling within the case-study region coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_case = y[0][0][355:480, 400:550]\n",
    "y_hat_case = y_hat[0][0][355:480, 400:550]\n",
    "mask_case = model.data.mask[355:480, 400:550]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(y_case.squeeze(), 'Observed FWI-reanalysis in the case-study region for 2019-04-02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(y_hat_case.squeeze(), f'Predicted FWI-reanalysis in the case-study region for 2019-04-02\\nAccuracy: \\\n",
    "{((y_case-y_hat_case).abs()<9.4)[mask_case.expand_as(y_case)].float().mean()*100:.2f}%*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>*Using half of MAD as the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot((y_case-y_hat_case).abs().squeeze(), f\"Error in predicted FWI-reanalysis for 2019-04-02\\nMAE: \\\n",
    "{((y_case-y_hat_case).abs())[mask_case.expand_as(y_case)].float().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trained with Box-Cox transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do inference on the model trained with Box-Cox transformed output variable, we would need the corresponding lambda value for the inverse transformation. The chekpoint used here requires the lambda = 0.1182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.boxcox = 0.1182\n",
    "hparams.checkpoint_file='/w/deepfwi/src/model/checkpoints/pre_trained/7/2_1/epoch_41_100.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model architecture and attach with the data\n",
    "model = get_model(hparams)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model.load_state_dict(torch.load(hparams.checkpoint_file)[\"state_dict\"])\n",
    "\n",
    "# Turn off the gradients\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor\n",
    "x = model.data[0][0].unsqueeze(0)\n",
    "\n",
    "# Ground truth tensor\n",
    "y = model.data[0][1].unsqueeze(0)\n",
    "\n",
    "# Predicted tensor\n",
    "y_hat = model(x).detach()\n",
    "y_hat = torch.from_numpy(\n",
    "    inv_boxcox(y_hat.cpu().numpy(), model.hparams.boxcox)\n",
    ")\n",
    "\n",
    "# Masking the prediction as done with the ground truth\n",
    "y_hat[torch.isnan(y)] = torch.tensor(float('nan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(y_hat.squeeze(), f'Predicted FWI-reanalysis after Box-Cox transformation for 2019-04-02\\nAccuracy: \\\n",
    "{((y-y_hat).abs()<9.4)[model.data.mask.expand_as(y)].float().mean()*100:.2f}%*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>*Using half of MAD as the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot((y-y_hat).abs().squeeze(), f\"Error in predicted FWI-reanalysis after Box-Cox transformation for 2019-04-02\\nMAE: \\\n",
    "{((y-y_hat).abs())[model.data.mask.expand_as(y)].float().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of passing inputs manually to the model, the `Trainer` can be used. It will run the prepared model over the entire data and generate the result metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trainer object responsible for running the model\n",
    "trainer = pl.Trainer(gpus=hparams.gpus)\n",
    "\n",
    "# Running inference with the supplied model\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did single day global forecast using 2-day input of Relative humidty, Temperature, Total precipitation, and Wind speed. The model gives accuracy of 93.36%, *MAE* of 2.608, and *MSE* of 21.452. We also looked at the error distribution of the prediction across the various regions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
